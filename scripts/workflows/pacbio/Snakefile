from os.path import join
from samples import Samples

"""
################################################################################
Author: https://github.com/nahanoo
This is the snakemake file for processing the pacbio samples. The assemblies
were created by someone else and directly integrated into the workflow.
The corrected reads outputted form canu are aligned to the wild-type genomes.
Then deletions and insertions are identified using
https://github.com/nahanoo/deletion_detection.
################################################################################
"""

work = '/work/FAC/FBM/DMF/smitri/evomicrocomm/genome_size/data/'

def get_strain(wildcards):
    """Returns the full strain name"""
    for strain,samples in Samples().strains.items():
        for sample in samples:
            if sample['name'] == wildcards.sample:
                return strain

def get_strain_abbreviation(wildcards):
    """Returns the full strain name"""
    for strain,samples in Samples().strains.items():
        for sample in samples:
            if sample['name'] == wildcards.sample:
                return Samples().abbreviations[strain]


def get_genbank(wildcards):
    """Returns genbank based on sample name"""
    for strain,samples in Samples().strains.items():
        for sample in samples:
            if sample['name'] == wildcards.sample:
                return join(work,'ancestors',Samples().abbreviations[strain],'bakta','assembly.contigs.polypolish.gbff')

def get_reference(wildcards):
    """Returns reference fasta based on sample name"""
    for strain,samples in Samples().strains.items():
        for sample in samples:
            if sample['name'] == wildcards.sample:
                return join(work,'ancestors',Samples().abbreviations[strain],'assembly.contigs.polypolish.fasta')
            
def get_genome_length(wildcards):
    genome_sizes = {
        'At':'5.3m',
        'Ct':'6.1m',
        'Ms':'3.7m',
        'Oa':'5.1m'}
    return genome_sizes[wildcards.sample[:2]]



#Aligning corrected reads to wild-type genome
rule mapping_corrected_reads:
    input:
        reference = get_reference,
        corrected_reads = join(work,'{sample}','corrected_reads.fasta')
    output:
        join(work,'{sample}','mapped_corrected_reads.sorted.bam')
    threads:
        4
    shell:
        """
        minimap2 --secondary=no -R '@RG\\tID:snippy\\tSM:snippy' -t 4 -ax map-pb {input} | samtools sort --threads 16 -o {output}
        samtools index {output}
        """

rule map_assemblies:
    input:
        reference = get_reference,
        assembly = join(work,'{sample}','assembly.contigs.racon.fasta')
    output:
        join(work,'{sample}','mapped_assembly.sorted.bam')
    threads:
        1
    shell:
        """
        minimap2 -t {threads} -ax asm5 {input} | samtools sort --threads 16 -o {output}
        samtools index {output}
        """


rule snippy:
    input:
        reference = get_genbank,
        bam = join(work,'{sample}','mapped_corrected_reads.sorted.bam'),
        contigs = join(work,'{sample}','assembly.fasta')
    output:
        outfile = join(work,'{sample}','snippy','snps.tab')
    threads:
        4
    params:
        outdir = join(work,'{sample}','snippy')
    shell:
        """
        snippy --cpus 4 --force --outdir \
        {params} --reference {input.reference} --ctgs {input.contigs}
        """


rule bakta:
    input:
        join(work,'{sample}','assembly.contigs.racon.fasta')
    output:
        join(work,'{sample}','bakta','assembly.contigs.racon.gbff')
    params:
        join(work,'{sample}','bakta')
    threads:
        4
    conda:
        "bakta"
    shell:
        """bakta --force --db ~/work/bakta/db/ --keep-contig-headers --threads {threads} {input} --output {params}
        """
        
rule deletion_detection:
    input:
        mutant = join(work,'{sample}','assembly.contigs.racon.fasta'),
        reference = get_genbank
    output:
        join(work,'{sample}','deletions.annotated.tsv'),
        join(work,'{sample}','plasmids.annotated.tsv')
    params:
        join(work,'{sample}'),

    threads:
        1
    shell:
        "detect_deletions --plot {input} {params}"


#Areas with no coverage are identified which are insertions (sequence present
#in evolded strain but not in wild-type)
rule insertion_detection:
    input:
        gbk = join(work,'{sample}','bakta','assembly.gbff'),
        reference = get_reference
    output:
        join(work,'{sample}','insertions.tsv'),
        join(work,'{sample}','insertions.annotated.tsv')
    params:
        join(work,'{sample}'),

    threads:
        1
    shell:
        "detect_insertions --plot {input} {params}"


rule hgt_detection:
    input:
        mutant = join(work,'{sample}','bakta','assembly.gbff'),
        ancestor = get_reference,
        references = join(work,'references')
    output:
        join(work,'{sample}','hgts.annotated.tsv'),
    params:
        out_dir = join(work,'{sample}')
    threads:
        1
    shell:
        "detect_hgts {input} {params}"

rule ise_scan:
    input:
        mutant = join(work,'{sample}','assembly.fasta')
    output:
        join(work,'{sample}','ise_scan','assembly.fasta.tsv')
    params:
        out_dir = join(work,'{sample}','ise_scan')
    threads:
        1
    shell:
        "isescan.py --seqfile {input} --output {params} --nthread {threads}"

#We also creat a report for the alignment file given us interesting stats
#For the report we need to store the labels of the plots as json
rule labels:
    output:
        join(work,'{sample}','labels.json')
    params:
        outdir = join(work,'{sample}'),
        strain = get_strain
    threads:
        1
    shell:
        """
        echo {params.strain}
        python create_labels.py {wildcards.sample} {params.strain} {params.outdir}
        """

#Creating report using https://github.com/nahanoo/gc_bias/tree/main/gc_bias
rule report:
    input:
        labels = join(work,'{sample}','labels.json'),
        reference = join(work,'{sample}','reference.fasta'),
        bam = join(work,'{sample}','mapped_corrected_reads.sorted.bam')
    output:
        join(work,'{sample}','report.md')
    params:
        outdir = join(work,'{sample}')
    threads:
        1
    shell:
        "report_bam_stats {input.reference} {input.bam} {input.labels} {params.outdir}"

#Because the assemblies were done by someone else, I also quickly assembled
#them withi miniams. Similar results, thus I'm sticking with previously made assemblies.
#Overlapping reads for miniasm
rule overlapping_corrected_reads:
    input:
        join(work,'{sample}','corrected_reads.fasta'),
    output:
        join(work,'{sample}','overlapped_corrected_reads.paf')
    threads:
        4
    shell:
        "minimap2 -x ava-pb -t {threads} {input} {input} > {output}"

#Running miniasm on overlapped reads
rule miniasm:
    input:
        reads = join(work,'{sample}','corrected_reads.fasta'),
        overlap = join(work,'{sample}','overlapped_corrected_reads.paf')
    output:
        gfa = join(work,'{sample}','assembly.miniasm.gfa'),
        fasta = join(work,'{sample}','assembly.miniasm.fasta')
    threads:
        4
    shell:
        """miniasm -f {input} > {output.gfa}
        awk '/^S/{{print ">"$2"\\n"$3}}' {output.gfa} > {output.fasta}
        """
rule canu:
    input:
        pacbio = join(work,'{sample}','corrected_reads.fasta')
    params:
        genome_length = get_genome_length,
        out_dir = join(work,'{sample}','canu'),
        prefix = 'assembly'
    output:
        join(work,'{sample}','canu','assembly.contigs.fasta')
    threads:
        4
    shell:
        """
        canu -assemble -corrected -p {params.prefix} -d {params.out_dir} useGrid=false genomeSize={params.genome_length} \
        -pacbio {input.pacbio}
        """

rule map_long_reads:
    input:
        reads = join(work,'{sample}','corrected_reads.fasta'),
        assembly = join(work,'{sample}','canu','assembly.contigs.fasta')
    output:
        join(work,'{sample}','assembly_correction.sam')
    threads:
        1
    shell:
        """
        minimap2 -t {threads} -ax map-pb {input.assembly} {input.reads} > {output}
        """

rule racon:
    input:
        fasta = join(work,'{sample}','canu','assembly.contigs.fasta'),
        fastq = join(work,'{sample}','corrected_reads.fasta'),
        alignment = join(work,'{sample}','assembly_correction.sam')
    threads:
        1
    output:
        join(work,'{sample}','assembly.contigs.racon.fasta')
    shell:
        """
        racon {input.fastq} {input.alignment} {input.fasta} > {output}
        """

rule sourmash:
    input:
        join(work,'{sample}','assembly.fasta')
    output:
        join(work,'{sample}','assembly.sig')
    threads:
        1
    shell:
        """
        sourmash sketch dna -p scaled=1000,k=31 {input} -o {output}
        """

rule pbmm2:
    input:
        reference = get_reference,
        reads = join(work,'{sample}','reads.fastq.gz')
    output:
        join(work,'{sample}','pbmm2.bam')
    threads:
        4
    shell:
        """
        pbmm2 align {input} {output} -j {threads} --sort --preset CCS --sample {wildcards.sample} --rg '@RG\tID:{wildcards.sample}'
        """

rule pbsvsig:
    input:
        join(work,'{sample}','pbmm2.bam')
    output:
        join(work,'{sample}','pbsv.svsig.gz')
    threads:
        1
    shell:
        """
        pbsv discover {input} {output}
        """

rule pbsvcall:
    input:
        reference = get_reference,
        sig = join(work,'{sample}','pbsv.svsig.gz')
    output:
        join(work,'{sample}','pbsv.var.vcf')
    threads:
        4
    shell:
        """
        pbsv call -j {threads} {input} {output}
        """

rule ipa:
    input:
        join(work,'{sample}','reads.fastq.gz')
    output:
        join(work,'{sample}','ipa','19-final','final.a_ctg.fasta')
    params:
        join(join(work,'{sample}','ipa'))
    threads:
        24
    shell:
        """
        ipa dist -i {input} --nthreads 24 --njobs 20 --run-dir {params} --cluster-args "qsub -S /bin/bash -N ipa.{rule} -cwd -q default -pe smp 24 -e qsub_log/ -o qsub_log/ -V"
        """

rule sniffles:
    input:
        join(work,'{sample}','mapped_corrected_reads.sorted.bam')
    output:
        join(work,'{sample}','sniffles.var.vcf')
    threads:
        8
    shell:
        """
        sniffles -t {threads} -i {input} -v {output}
        """

rule samtools_depth:
    input:
        bam = join(work,'{sample}','mapped_corrected_reads.sorted.bam')
    output:
        samtools_depth = join(work,'{sample}','depth_Q_0.tsv'),
        concat = join(work,'{sample}','depth_Q_0.concat.csv')
    threads:
        1
    shell:
        """
        samtools depth -aa -Q 0 {input.bam} > {output.samtools_depth}
        python concat_depth.py {wildcards.sample}
        """